*--
layout: post
title: "May 28 2018 RRG Notes"
date: 2018-05-28 12:00 -0500
categories: rrg_notes
*--

## [Created Already In Motion](https://www.greaterwrong.com/posts/CuSTqHgeK4CMpWYTe/created-already-in-motion)
* Minds must implement some kind of basic logic in order for persuasion based upon logic to work
* A *dynamic* is something that happens inside a cognitive system, not in the data that the system manipulates
* There is no argument that is universally persuasive -- no matter how persuasive your argument is, you won't be able to convince a rock

## [The Bedrock of Fairness](https://www.greaterwrong.com/posts/iAxkfiyG8WizPSPbq/the-bedrock-of-fairness)
* Is fairness a concept in the world, or is it a concept in our minds?
* Is fairness that which crosses the gap between people and convinces someone else that one is being moral, and someone else is not?
* There is no procedure that is so inherently fair that everyone will automatically agree to it
* We are often more sure of the outcome of a fair procedure than we are of the procedure itself

## [Moral Complexities](https://www.greaterwrong.com/posts/SbdCX6A5AGyyfhdmh/moral-complexities)
* Questions for those who believe that morality is a preference
    * Why do people act as if they mean different things by, "I want X," and "It is *right* that I should have X?"
    * When and why do people change their terminal values? Is it meaningful to talk about "moral progress" and "moral error"?
    * Why and how do people do things that they "know they shouldn't" or things they "know are wrong"?
* Questions for those who believe that morality is given
    * Is it possible for everyone to be wrong about morality, and also be wrong about how to update their moral beliefs? 
    * How would you know that you were in such a world?
    * How does a world in which a moral proposition is true differ from a world in which a moral proposition is false?
    * What prevents an alien mind from viewing morality very differently from us?
    * Why does morality look so much like the output of natural selection?

## [Is Morality Preference?](https://www.greaterwrong.com/posts/F5WLc7hCxkB4X4yD4/is-morality-preference)
* Subhan: No reason to talk about morality as being distinct from what people want
* Obert: Morality is distinct from desire
* Is there a basic difference between "desire" and "duty"?
* Somehow society went from Old Testament attitudes, where certain actions needed no moral justification, to a more modern conception of morality, where actions do need justification
* When we talk of moral progress, are we engaging in anachronism? Are we judging the past by the standards of the present and finding it wanting?

## [Is Morality Given?](https://www.greaterwrong.com/posts/iQNKfYb7aRYopojTX/is-morality-given)
* Continuation of "Is Morality Preference?"
* If we encountered a carnivorous alien species who thought it was morally right to kill, and morally wrong *not* to kill, would they be morally wrong in killing a human? By whose morality?
* Is it possible for humans, or even all humanity, to be irretrievably morally wrong?
* Is there any difference between saying, "I choose to do X because it is moral," and "I choose to do X because God wills it?"
* There are no preferences that are inherently more moral or right in a world that consists solely of elementary particles interacting accroding to the laws of physics
* But, it might be better if we acted as if morality were given

## [Where Recursive Justification Hits Bottom](https://www.greaterwrong.com/posts/C8nEXTcjZb9oauTCW/where-recursive-justification-hits-bottom)
* In the end, we adopt beliefs because they work, not because they will convince a hypothetical philosopher who has no priors
* We trust things like Occam's Razor not out of any deep philosophical reason, but "merely" because it's worked well for us in the past
* We must always put forth our best effort, knowing the entire time that we are flawed reasoners
* Your beliefs don't change the capabilities of your mind -- they only change the sorts of problems that you apply your mind to
* Rationalists are not out to win debates with hypothetical philosophers, they are out to form correct beliefs about the world
* The point isn't to be reflectively self-consistent, the point is to win
* Reflective self-consistency is a means to that end
* The important thing is to not exclude anything from question, even if the answer ends up being a recursive loop
